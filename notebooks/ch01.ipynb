{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第１章: 準備運動\n",
    "https://nlp100.github.io/ja/ch01.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00.文字列の逆順\n",
    "文字列”stressed”の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ．\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desserts\n"
     ]
    }
   ],
   "source": [
    "string = 'stressed'\n",
    "string_inverse = string[::-1]\n",
    "print(string_inverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01.「パタトクカシーー」\n",
    "「パトカー」＋「タクシー」の文字を先頭から交互に連結して文字列「パタトクカシーー」を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パタトクカシーー\n"
     ]
    }
   ],
   "source": [
    "str1 = \"パトカー\"\n",
    "str2 = \"タクシー\"\n",
    "str3 = ''.join([a+b for a,b in zip(str1, str2)])\n",
    "print(str3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. 円周率\n",
    "“Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.”という文を単語に分解し，各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.'\n",
    "result_list = [len(word.replace(',', '').replace('.', '')) for word in sentence.split()]\n",
    "print(result_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. 元素記号\n",
    "“Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.”という文を単語に分解し，1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字，それ以外の単語は先頭の2文字を取り出し，取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ．\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'H': 1, 'He': 2, 'Li': 3, 'Be': 4, 'B': 5, 'C': 6, 'N': 7, 'O': 8, 'F': 9, 'Ne': 10, 'Na': 11, 'Mi': 12, 'Al': 13, 'Si': 14, 'P': 15, 'S': 16, 'Cl': 17, 'Ar': 18, 'K': 19, 'Ca': 20}\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.'\n",
    "num_list = [1, 5, 6, 7, 8, 9, 15, 16, 19]\n",
    "result_dict = {i+1:word[0] if i+1 in num_list else word[:2] for i, word in enumerate(sentence.split())} # 先頭からの位置をキーとして取り出した単語をマップする辞書\n",
    "result_dict = {value:key for key, value in result_dict.items()} # keyとvalueの入れ替え\n",
    "print(result_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. n-gram\n",
    "与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．この関数を用い，”I am an NLPer”という文から単語bi-gram，文字bi-gramを得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I ', ' a', 'am', 'm ', ' a', 'an', 'n ', ' N', 'NL', 'LP', 'Pe', 'er']\n",
      "[['I', 'am'], ['am', 'an'], ['an', 'NLPer']]\n"
     ]
    }
   ],
   "source": [
    "# n-gramを文字列or配列の引数から取得する関数\n",
    "def get_n_gram(sentence, n):\n",
    "    return [sentence[i:i+n] for i in range(len(sentence)-n+1)]\n",
    "\n",
    "sentence = 'I am an NLPer'\n",
    "# 文字bi-gram\n",
    "print(get_n_gram(sentence, 2))\n",
    "\n",
    "# 単語bi-gram\n",
    "print(get_n_gram(sentence.split(), 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. 集合\n",
    "“paraparaparadise”と”paragraph”に含まれる文字bi-gramの集合を，それぞれ, XとYとして求め，XとYの和集合，積集合，差集合を求めよ．さらに，’se’というbi-gramがXおよびYに含まれるかどうかを調べよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pa', 'se', 'gr', 'is', 'ra', 'di', 'ph', 'ag', 'ad', 'ap', 'ar'}\n",
      "{'ap', 'ar', 'pa', 'ra'}\n",
      "{'ad', 'se', 'is', 'di'}\n",
      "X: True, Y: False\n"
     ]
    }
   ],
   "source": [
    "word1 = 'paraparaparadise'\n",
    "word2 = 'paragraph'\n",
    "\n",
    "X = set(get_n_gram(word1, 2))\n",
    "Y = set(get_n_gram(word2, 2))\n",
    "\n",
    "# 和集合\n",
    "print(X|Y)\n",
    "# 積集合\n",
    "print(X&Y)\n",
    "# 差集合\n",
    "print(X-Y)\n",
    "# 'se'が含まれるかどうか\n",
    "print(f\"X: {'se' in X}, Y: {'se' in Y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. テンプレートによる文生成\n",
    "引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ．さらに，x=12, y=”気温”, z=22.4として，実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12時の気温は22.4\n"
     ]
    }
   ],
   "source": [
    "# 半角スペースを開けて入力する\n",
    "x, y, z = input().split()\n",
    "print(f'{x}時の{y}は{z}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08. 暗号文\n",
    "与えられた文字列の各文字を，以下の仕様で変換する関数cipherを実装せよ．\n",
    "- 英小文字ならば(219 - 文字コード)の文字に置換\n",
    "- その他の文字はそのまま出力\n",
    "\n",
    "この関数を用い，英語のメッセージを暗号化・復号化せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tsrh rh z kvm. Tsrh rh krmvzkkov. PPAP.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 全角英字には非対応かも...\n",
    "def cipher(sentence):\n",
    "    return ''.join([chr(219-ord(ch)) if ch.islower() else ch for ch in sentence])\n",
    "\n",
    "sentence = 'This is a pen. This is pineapple. PPAP.'\n",
    "cipher(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09. Typoglycemia\n",
    "スペースで区切られた単語列に対して，各単語の先頭と末尾の文字は残し，それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ．ただし，長さが４以下の単語は並び替えないこととする．適当な英語の文（例えば”I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .”）を与え，その実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cdul’ont beviele that I cluod alaculty utrnanedsd what I was rnidaeg : the peenaohmnl peowr of the hamun mind .\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# 単語の先頭と末尾意外をシャッフル(長さ5以上の時のみ)\n",
    "def shuffle_word(word):\n",
    "    if len(word) > 4:\n",
    "        word = word[0] + ''.join(random.sample(word[1:-1], len(word[1:-1]))) + word[-1]\n",
    "    return word\n",
    "\n",
    "sentence = \"I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
    "result = ' '.join(map(shuffle_word, sentence.split()))\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
